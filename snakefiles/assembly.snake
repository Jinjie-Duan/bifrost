import re
import pandas
from ruamel.yaml import YAML
import sys


configfile: os.path.join(os.path.dirname(workflow.snakefile), "../config.yaml")
# requires --config R1_reads={read_location},R2_reads={read_location}
sample = config["Sample"]
R1 = config["R1_reads"],
R2 = config["R2_reads"],
global_threads = config["global"]["threads"]
global_memory_in_GB = config["global"]["memory"]

yaml = YAML(typ='safe')
yaml.default_flow_style = False
with open(sample, "r") as yaml_stream:
    config_sample = yaml.load(yaml_stream)


# my understanding is all helps specify final output
onsuccess:
    print("Workflow complete")
    output = ["assembly_status.txt"]
    with open(output[0], "w") as status:
        status.write("Success\n")
onerror:
    print("Workflow error")
    output = ["assembly_status.txt"]
    with open(output[0], "w") as status:
        status.write("Failure\n")

rule all:
    input:
        "assembly",
        "assembly/prokka",
        "assembly/contigs.vcf"


# rule run__assembly:
#     message:
#         "Denovo assembly of reads"
#     input:
#         reads = (R1, R2)
#     output:
#         "assembly_done"
#     params:
#         adapters = os.path.join(os.path.dirname(workflow.snakefile), "../resources/adapters.fasta")
#     shell:
#         """
#         mkdir assembly
#         cd assembly
#         bbduk.sh in={input.reads[0]} in2={input.reads[1]} out=filtered.fq ref={params.adapters} ktrim=r k=23 mink=11 hdist=1 tbo minavgquality=14 &>> assembly.log
#         bbmerge.sh in=filtered.fq out=merged.fq outu=unmerged.fq &>> assembly.log
#         spades.py -k 21,33,55,77 -s merged.fq --s1 unmerged.fq -o spades &>> assembly.log
#         mv spades/contigs.fasta spades_contigs.fasta
#         cd ..
#         touch assembly_done
#         """

rule setup:
    message:
        "Running step: {rule}"
    output:
        dir = "assembly"
    shell:
        "mkdir {output}"


rule setup__filter_reads_with_bbduk:
    message:
        "Running step: {rule}"
    input:
        dir = "assembly",
        reads = (R1, R2)
    output:
        filtered_reads = "assembly/filtered.fastq"
    params:
        adapters = os.path.join(os.path.dirname(workflow.snakefile), "../resources/adapters.fasta")
    threads:
        global_threads
    resources:
        memory_in_GB = global_memory_in_GB
    log:
        "assembly/log/setup__filter_reads_with_bbduk.log"
    benchmark:
        "assembly/benchmarks/setup__filter_reads_with_bbduk.benchmark"
    run:
        if os.path.isfile("qcquickie/filtered.fastq"):
            shell("ln -s {} {}".format(os.path.realpath("qcquickie/filtered.fastq"), output.filtered_reads))
        else:
            shell("bbduk.sh in={input.reads[0]} in2={input.reads[1]} out={output.filtered_reads} ref={params.adapters} ktrim=r k=23 mink=11 hdist=1 tbo minavgquality=14 &> {log}")


# rule assembly_check__combine_reads_with_bbmerge:
#     message:
#         "Running step: {rule}"
#     input:
#         filtered_reads = "assembly/filtered.fastq"
#     output:
#         merged_reads = "assembly/merged.fastq",
#         unmerged_reads = "assembly/unmerged.fastq"
#     threads:
#         global_threads
#     resources:
#         memory_in_GB = global_memory_in_GB
#     log:
#         "assembly/log/assembly_check__combine_reads_with_bbmerge.log"
#     benchmark:
#         "assembly/benchmarks/assembly_check__combine_reads_with_bbmerge.benchmark"
#     run:
#         if os.path.isfile("qcquickie/merged.fastq") and os.path.isfile("qcquickie/unmerged.fastq"):
#             shell("ln -s {} {}".format(os.path.realpath("qcquickie/merged.fastq"), output.merged_reads))
#             shell("ln -s {} {}".format(os.path.realpath("qcquickie/unmerged.fastq"), output.unmerged_reads))
#         else:
#             shell("bbmerge.sh in={input.filtered_reads} out={output.merged_reads} outu={output.unmerged_reads} &> {log}")


# rule assembly__spades:
#     input:
#         merged_reads = "assembly/merged.fastq",
#         unmerged_reads = "assembly/unmerged.fastq"
#     output:
#         assembly = "assembly/spades",
#         contigs = "assembly/spades/contigs.fasta",
#     threads:
#         global_threads
#     resources:
#         memory_in_GB = global_memory_in_GB
#     log:
#         "assembly/log/assembly__spades.log"
#     benchmark:
#         "assembly/benchmarks/assembly__spades.benchmark"
#     shell:
#         """
#         spades.py -k 21,33,55,77 -s {input.merged_reads} --12 {input.unmerged_reads} -o {output.assembly} --careful &> {log}
#         mv spades/contigs.fasta contigs.fasta
#         """


rule assembly__skesa:
    message:
        "Running step: {rule}"
    input:
        filtered_reads = "assembly/filtered.fastq",
    output:
        contigs = "assembly/contigs.fasta",
    threads:
        global_threads
    resources:
        memory_in_GB = global_memory_in_GB
    log:
        "assembly/log/assembly__skesa.log"
    benchmark:
        "assembly/benchmarks/assembly__skesa.benchmark"
    shell:
        "skesa --cores {threads} --memory {resources.memory_in_GB} --use_paired_ends --fastq {input.filtered_reads} --contigs_out {output.contigs} &> {log}"


rule post_assembly__stats:
    message:
        "Running step: {rule}"
    input:
        contigs = "assembly/contigs.fasta"
    output:
        stats = touch("assembly/post_assermbly__stats")
    threads:
        global_threads
    resources:
        memory_in_GB = global_memory_in_GB
    log:
        "assembly/log/post_assembly__stats.log"
    benchmark:
        "assembly/benchmarks/post_assembly__stats.benchmark"
    shell:
        "stats.sh {input.contigs} &> {log}"


rule post_assembly__mapping:
    message:
        "Running step: {rule}"
    input:
        contigs = "assembly/contigs.fasta",
        filtered_reads = "assembly/filtered.fastq",
    output:
        mapped = "assembly/contigs.sam"
    threads:
        global_threads
    resources:
        memory_in_GB = global_memory_in_GB
    log:
        "assembly/log/post_assembly__mapping.log"
    benchmark:
        "assembly/benchmarks/post_assembly__mapping.benchmark"
    shell:
        "bbmap.sh threads={threads} -Xmx{resources.memory_in_GB}G ref={input.contigs} in={input.filtered_reads} out={output.mapped} &> {log}"


rule post_assembly__pileup:
    message:
        "Running step: {rule}"
    input:
        mapped = "assembly/contigs.sam"
    output:
        coverage = "assembly/contigs.cov",
        pileup = "assembly/contigs.pileup"
    threads:
        global_threads
    resources:
        memory_in_GB = global_memory_in_GB
    log:
        "assembly/log/post_assembly__pileup.log"
    benchmark:
        "assembly/benchmarks/post_assembly__pileup.benchmark"
    shell:
        "pileup.sh threads={threads} -Xmx{resources.memory_in_GB}G in={input.mapped} basecov={output.coverage} out={output.pileup} &> {log}"


rule summarize__depth:
    message:
        "Running step: {rule}"
    input:
        coverage = "assembly/contigs.cov"
    output:
        contig_depth_yaml = "assembly/contigs.sum.cov",
        binned_depth_yaml = "assembly/contigs.bin.cov"
    threads:
        global_threads
    resources:
        memory_in_GB = global_memory_in_GB
    log:
        "assembly/log/summarize__bin_coverage.log"
    benchmark:
        "assembly/benchmarks/summarize__bin_coverage.benchmark"
    script:
        os.path.join(os.path.dirname(workflow.snakefile), "../scripts/summarize_depth.py")


rule post_assembly__call_variants:
    message:
        "Running step: {rule}"
    input:
        contigs = "assembly/contigs.fasta",
        mapped = "assembly/contigs.pileup",
    output:
        variants = "assembly/contigs.vcf",
    threads:
        global_threads
    resources:
        memory_in_GB = global_memory_in_GB
    log:
        "assembly/log/post_assembly__call_variants.log"
    benchmark:
        "assembly/benchmarks/post_assembly__call_variants.benchmark"
    shell:
        "callvariants.sh in={input.mapped} vcf={output.variants} ref={input.contigs} ploidy=1 clearfilters &> {log}"


rule summarize__variants:
    message:
        "Running step: {rule}"
    input:
        variants = "assembly/contigs.vcf",
    output:
        variants_yaml = "assembly/contigs.variants",
    threads:
        global_threads
    resources:
        memory_in_GB = global_memory_in_GB
    log:
        "assembly/log/summarize__variants.log"
    benchmark:
        "assembly/benchmarks/summarize__variants.benchmark"
    script:
        os.path.join(os.path.dirname(workflow.snakefile), "../scripts/summarize_variants.py")


rule post_assembly__annotate:
    message:
        "Running step: {rule}"
    input:
        contigs = "assembly/contigs.fasta"
    output:
        prokka = "assembly/prokka"
    threads:
        global_threads
    resources:
        memory_in_GB = global_memory_in_GB
    log:
        "assembly/log/post_assembly__annotate.log"
    benchmark:
        "assembly/benchmarks/post_assembly__annotate.benchmark"
    shell:
        "prokka --cpus {threads} --centre XXX --compliant --outdir {output.prokka} {input.contigs} &> {log}"
