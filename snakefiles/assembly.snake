import re
import pandas
from ruamel.yaml import YAML
import sys
sys.path.append(os.path.join(os.path.dirname(workflow.snakefile), "../"))
import scripts.serum as serum

configfile: os.path.join(os.path.dirname(workflow.snakefile), "../config.yaml")
# requires --config R1_reads={read_location},R2_reads={read_location}
sample = config["Sample"]
R1 = config["R1_reads"],
R2 = config["R2_reads"],
global_threads = config["global"]["threads"]
global_memory_in_GB = config["global"]["memory"]

yaml = YAML(typ='safe')
yaml.default_flow_style = False
with open(sample, "r") as yaml_stream:
    config_sample = yaml.load(yaml_stream)


# my understanding is all helps specify final output
onsuccess:
    print("Workflow complete")
    output = ["assembly_status.txt"]
    with open(output[0], "w") as status:
        status.write("Success\n")
onerror:
    print("Workflow error")
    output = ["assembly_status.txt"]
    with open(output[0], "w") as status:
        status.write("Failure\n")

rule all:
    input:
        "assembly",
        "assembly/spades"


# rule run__assembly:
#     message:
#         "Denovo assembly of reads"
#     input:
#         reads = (R1, R2)
#     output:
#         "assembly_done"
#     params:
#         adapters = os.path.join(os.path.dirname(workflow.snakefile), "../resources/adapters.fasta")
#     shell:
#         """
#         mkdir assembly
#         cd assembly
#         bbduk.sh in={input.reads[0]} in2={input.reads[1]} out=filtered.fq ref={params.adapters} ktrim=r k=23 mink=11 hdist=1 tbo minavgquality=14 &>> assembly.log
#         bbmerge.sh in=filtered.fq out=merged.fq outu=unmerged.fq &>> assembly.log
#         spades.py -k 21,33,55,77 -s merged.fq --s1 unmerged.fq -o spades &>> assembly.log
#         mv spades/contigs.fasta spades_contigs.fasta
#         cd ..
#         touch assembly_done
#         """

rule setup:
    output:
        dir = "assembly"
    shell:
        "mkdir {output}"


rule setup__filter_reads_with_bbduk:
    message:
        "Running step: {rule}"
    input:
        dir = "assembly",
        reads = (R1, R2)
    output:
        filtered_reads = "assembly/filtered.fastq"
    params:
        adapters = os.path.join(os.path.dirname(workflow.snakefile), "../resources/adapters.fasta")
    threads:
        global_threads
    resources:
        memory_in_GB = global_memory_in_GB
    log:
        "assembly/log/setup__filter_reads_with_bbduk.log"
    benchmark:
        "assembly/benchmarks/setup__filter_reads_with_bbduk.benchmark"
    run:
        if os.path.isfile("qcquickie/filtered.fastq"):
            shell("ln -s {} {}".format(os.path.realpath("qcquickie/filtered.fastq"), output.filtered_reads))
        else:
            shell("bbduk.sh in={input.reads[0]} in2={input.reads[1]} out={output.filtered_reads} ref={params.adapters} ktrim=r k=23 mink=11 hdist=1 tbo minavgquality=14 &> {log}")


rule assembly_check__combine_reads_with_bbmerge:
    message:
        "Running step: {rule}"
    input:
        filtered_reads = "assembly/filtered.fastq"
    output:
        merged_reads = "assembly/merged.fastq",
        unmerged_reads = "assembly/unmerged.fastq"
    threads:
        global_threads
    resources:
        memory_in_GB = global_memory_in_GB
    log:
        "assembly/log/assembly_check__combine_reads_with_bbmerge.log"
    benchmark:
        "assembly/benchmarks/assembly_check__combine_reads_with_bbmerge.benchmark"
    run:
        if os.path.isfile("qcquickie/merged.fastq") and os.path.isfile("qcquickie/unmerged.fastq"):
            shell("ln -s {} {}".format(os.path.realpath("qcquickie/merged.fastq"), output.merged_reads))
            shell("ln -s {} {}".format(os.path.realpath("qcquickie/unmerged.fastq"), output.unmerged_reads))
        else:
            shell("bbmerge.sh in={input.filtered_reads} out={output.merged_reads} outu={output.unmerged_reads} &> {log}")


rule assembly__spades:
    input:
        merged_reads = "assembly/merged.fastq",
        unmerged_reads = "assembly/unmerged.fastq"
    output:
        assembly = "assembly/spades"
        contigs = "assembly/spades/contigs.fasta"
    threads:
        global_threads
    resources:
        memory_in_GB = global_memory_in_GB
    log:
        "assembly/log/assembly__spades.log"
    benchmark:
        "assembly/benchmarks/assembly__spades.benchmark"
    shell:
        "spades.py -k 21,33,55,77 -s {input.merged_reads} --12 {input.unmerged_reads} -o {output.assembly} --careful &> {log}"


#stats.sh
rule post_assembly__stats:
    input:
        contigs = "assembly/spades/contigs.fasta"
    output:
        stats = touch("assembly/post_assermbly__stats")
    threads:
        global_threads
    resources:
        memory_in_GB = global_memory_in_GB
    log:
        "assembly/log/post_assembly__stats.log"
    benchmark:
        "assembly/benchmarks/post_assembly__stats.benchmark"
    shell:
        "stats.sh {input.contigs} &> {log}"


rule post_assembly__mapping:
    input:
        contigs = "assembly/spades/contigs.fasta"
        filtered_reads = "assembly/filtered.fastq"
    output:
        mapped = "assembly/contigs.sam"
    threads:
        global_threads
    resources:
        memory_in_GB = global_memory_in_GB
    log:
        "assembly/log/post_assembly__mapping.log"
    benchmark:
        "assembly/benchmarks/post_assembly__mapping.benchmark"
    shell:
        "bbmap.sh threads={threads} -Xmx{resources.memory_in_GB}G ref={input.contigs} in={input.filtered_reads} out={output.mapped} &> {log}"


rule post_assembly__pileup:
    input:
        mapped = "assembly/contigs.pileup"
    output:
        coverage = "assembly/contigs.cov",
        pileup = "assembly/contigs.pileup"
    threads:
        global_threads
    resources:
        memory_in_GB = global_memory_in_GB
    log:
        "assembly/log/post_assembly__pileup.log"
    benchmark:
        "assembly/benchmarks/post_assembly__pileup.benchmark"
    shell:
        "pileup.sh threads={threads} -Xmx{resources.memory_in_GB}G in={input.mapped} basecov={output.coverage} out={output.pileup} &> {log}"


rule post_assembly__call_variants:
    input:
        contigs = "assembly/contigs.fasta"
        mapped = "assembly/contigs.pileup"
    output:
        variants = "assembly/contigs.vcf"
    threads:
        global_threads
    resources:
        memory_in_GB = global_memory_in_GB
    log:
        "assembly/log/post_assembly__call_variants.log"
    benchmark:
        "assembly/benchmarks/post_assembly__call_variants.benchmark"
    shell:
        "callvariants.sh in={input.mapped} vcf={output.variants} ref={input.contigs} ploidy=1 rarity=0.0 clearfilters"


rule post_assembly__annotate:
    input:
        contigs = "assembly/contigs.fasta"
        mapped = "assembly/contigs.pileup"
    output:
        variants = "assembly/contigs.vcf"
    threads:
        global_threads
    resources:
        memory_in_GB = global_memory_in_GB
    log:
        "assembly/log/post_assembly__call_variants.log"
    benchmark:
        "assembly/benchmarks/post_assembly__call_variants.benchmark"
#prokka
#probably re add mapping steps as well

