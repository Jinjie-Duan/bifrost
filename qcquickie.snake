import re
import pandas
# from pytools.persistent_dict import PersistentDict
# size estimation from kmers as well with jellyfish?
# storage = PersistentDict("qcquickie_storage")

configfile: "config/config.yaml"
# requires --config R1_reads={read_location},R2_reads={read_location}
sample = "Test"
R1 = config["R1_reads"],
R2 = config["R2_reads"],

# my understanding is all helps specify final output
onsuccess:
    print("Workflow complete")
    output = ["status.txt"]
    with open(output[0], "w") as status:
        status.write("Success")
onerror:
    print("Workflow error")
    output = ["status.txt"]
    with open(output[0], "w") as status:
        status.write("Failure")

rule all:
    input:
        # analysis/rule run__Kraken_on_reads
        # analysis/set_species_file
        # analysis/run__Ariba_MLST_on_reads
        # analysis/run__Ariba_resfinder_on_reads
        # summarize/script__summarize_kraken_report
        "report.txt"

rule generateReport:
    message:
        "INFO: Collating results"
    input:
        "mlst"
    output:
        "report.txt"
    run:
        with open(output[0], "w") as report:
            with open("mlst/mlst_report.tsv") as mlst:
                for line in mlst:
                    report.write(line)


rule run__tadpole_on_trimmed_reads:
    message:
        "Denovo assembly of normalized reads"
    input:
        normalized_reads = ("reads/trimmed_R1.fastq.gz", "reads/trimmed_R2.fastq.gz")
    output:
        contigs = "contigs.fasta",
        log = "log/tadpole.log"
    params:
        options = "".join(config["tadpole"]["options"])
    log:
        "log/tadpole.log"
    shell:
        "tadpole.py in={input.normalized_reads[0]} in2={input.normalized_reads[1]} out={output.contigs} {params.options} &> {log}"


